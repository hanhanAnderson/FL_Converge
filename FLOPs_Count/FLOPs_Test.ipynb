{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from fvcore.nn import FlopCountAnalysis\n",
    "from  fvcore.nn import flop_count_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fvcore.nn import parameter_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG Related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self, vgg_name):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = self._make_layers(cfg[vgg_name])\n",
    "        self.classifier = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.features(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "\n",
    "    def _make_layers(self, cfg):\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        for x in cfg:\n",
    "            if x == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else:\n",
    "                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n",
    "                           nn.BatchNorm2d(x),\n",
    "                           nn.ReLU(inplace=True)]\n",
    "                in_channels = x\n",
    "        layers += [nn.AvgPool2d(kernel_size=1, stride=1)]\n",
    "        return nn.Sequential(*layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::max_pool2d encountered 5 time(s)\n",
      "Unsupported operator aten::avg_pool2d encountered 1 time(s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total FLOPs: 153527296\n",
      "| module                | #parameters or shape   | #flops    |\n",
      "|:----------------------|:-----------------------|:----------|\n",
      "| model                 | 9.231M                 | 0.154G    |\n",
      "|  features             |  9.226M                |  0.154G   |\n",
      "|   features.0          |   1.792K               |   1.769M  |\n",
      "|    features.0.weight  |    (64, 3, 3, 3)       |           |\n",
      "|    features.0.bias    |    (64,)               |           |\n",
      "|   features.1          |   0.128K               |   0.328M  |\n",
      "|    features.1.weight  |    (64,)               |           |\n",
      "|    features.1.bias    |    (64,)               |           |\n",
      "|   features.4          |   73.856K              |   18.874M |\n",
      "|    features.4.weight  |    (128, 64, 3, 3)     |           |\n",
      "|    features.4.bias    |    (128,)              |           |\n",
      "|   features.5          |   0.256K               |   0.164M  |\n",
      "|    features.5.weight  |    (128,)              |           |\n",
      "|    features.5.bias    |    (128,)              |           |\n",
      "|   features.8          |   0.295M               |   18.874M |\n",
      "|    features.8.weight  |    (256, 128, 3, 3)    |           |\n",
      "|    features.8.bias    |    (256,)              |           |\n",
      "|   features.9          |   0.512K               |   81.92K  |\n",
      "|    features.9.weight  |    (256,)              |           |\n",
      "|    features.9.bias    |    (256,)              |           |\n",
      "|   features.11         |   0.59M                |   37.749M |\n",
      "|    features.11.weight |    (256, 256, 3, 3)    |           |\n",
      "|    features.11.bias   |    (256,)              |           |\n",
      "|   features.12         |   0.512K               |   81.92K  |\n",
      "|    features.12.weight |    (256,)              |           |\n",
      "|    features.12.bias   |    (256,)              |           |\n",
      "|   features.15         |   1.18M                |   18.874M |\n",
      "|    features.15.weight |    (512, 256, 3, 3)    |           |\n",
      "|    features.15.bias   |    (512,)              |           |\n",
      "|   features.16         |   1.024K               |   40.96K  |\n",
      "|    features.16.weight |    (512,)              |           |\n",
      "|    features.16.bias   |    (512,)              |           |\n",
      "|   features.18         |   2.36M                |   37.749M |\n",
      "|    features.18.weight |    (512, 512, 3, 3)    |           |\n",
      "|    features.18.bias   |    (512,)              |           |\n",
      "|   features.19         |   1.024K               |   40.96K  |\n",
      "|    features.19.weight |    (512,)              |           |\n",
      "|    features.19.bias   |    (512,)              |           |\n",
      "|   features.22         |   2.36M                |   9.437M  |\n",
      "|    features.22.weight |    (512, 512, 3, 3)    |           |\n",
      "|    features.22.bias   |    (512,)              |           |\n",
      "|   features.23         |   1.024K               |   10.24K  |\n",
      "|    features.23.weight |    (512,)              |           |\n",
      "|    features.23.bias   |    (512,)              |           |\n",
      "|   features.25         |   2.36M                |   9.437M  |\n",
      "|    features.25.weight |    (512, 512, 3, 3)    |           |\n",
      "|    features.25.bias   |    (512,)              |           |\n",
      "|   features.26         |   1.024K               |   10.24K  |\n",
      "|    features.26.weight |    (512,)              |           |\n",
      "|    features.26.bias   |    (512,)              |           |\n",
      "|  classifier           |  5.13K                 |  5.12K    |\n",
      "|   classifier.weight   |   (10, 512)            |           |\n",
      "|   classifier.bias     |   (10,)                |           |\n"
     ]
    }
   ],
   "source": [
    "net_glob = VGG('VGG11').to(\"cuda\")\n",
    "inp = torch.randn([1,3,32,32]).cuda()\n",
    "\n",
    "# log_probs = net_glob(inp)\n",
    "# inp = torch.randn([3,32,32]).cuda()\n",
    "flops_cnn = FlopCountAnalysis(net_glob, inp)\n",
    "print(\"Total FLOPs: \" + str(flops_cnn.total()))\n",
    "print(flop_count_table(flops_cnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "VGG(\n",
    "  (features): Sequential(\n",
    "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (2): ReLU(inplace=True)\n",
    "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (6): ReLU(inplace=True)\n",
    "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (10): ReLU(inplace=True)\n",
    "    (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (13): ReLU(inplace=True)\n",
    "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (17): ReLU(inplace=True)\n",
    "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (20): ReLU(inplace=True)\n",
    "    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (24): ReLU(inplace=True)\n",
    "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (27): ReLU(inplace=True)\n",
    "    (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "    (29): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
    "  )\n",
    "  (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN CIFAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::max_pool2d encountered 2 time(s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total FLOPs: 653800\n",
      "| module         | #parameters or shape   | #flops   |\n",
      "|:---------------|:-----------------------|:---------|\n",
      "| model          | 64.102K                | 0.654M   |\n",
      "|  conv1         |  0.456K                |  0.353M  |\n",
      "|   conv1.weight |   (6, 3, 5, 5)         |          |\n",
      "|   conv1.bias   |   (6,)                 |          |\n",
      "|  conv2         |  2.416K                |  0.24M   |\n",
      "|   conv2.weight |   (16, 6, 5, 5)        |          |\n",
      "|   conv2.bias   |   (16,)                |          |\n",
      "|  fc1           |  48.12K                |  48K     |\n",
      "|   fc1.weight   |   (120, 400)           |          |\n",
      "|   fc1.bias     |   (120,)               |          |\n",
      "|  fc2           |  12.1K                 |  12K     |\n",
      "|   fc2.weight   |   (100, 120)           |          |\n",
      "|   fc2.bias     |   (100,)               |          |\n",
      "|  fc3           |  1.01K                 |  1K      |\n",
      "|   fc3.weight   |   (10, 100)            |          |\n",
      "|   fc3.bias     |   (10,)                |          |\n"
     ]
    }
   ],
   "source": [
    "class Full_CNNCifar(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(Full_CNNCifar, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 100)\n",
    "        self.fc3 = nn.Linear(100, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "net_glob = Full_CNNCifar(num_classes = 10).to(\"cuda\")\n",
    "inp = torch.randn([1,3,32,32]).cuda()\n",
    "\n",
    "# log_probs = net_glob(inp)\n",
    "# inp = torch.randn([3,32,32]).cuda()\n",
    "flops_cnn = FlopCountAnalysis(net_glob, inp)\n",
    "print(\"Total FLOPs: \" + str(flops_cnn.total()))\n",
    "print(flop_count_table(flops_cnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::max_pool2d encountered 2 time(s)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "653800"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FlopCountAnalysis(net_glob, inp).total()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'': 64102,\n",
       "             'conv1': 456,\n",
       "             'conv1.weight': 450,\n",
       "             'conv1.bias': 6,\n",
       "             'conv2': 2416,\n",
       "             'conv2.weight': 2400,\n",
       "             'conv2.bias': 16,\n",
       "             'fc1': 48120,\n",
       "             'fc1.weight': 48000,\n",
       "             'fc1.bias': 120,\n",
       "             'fc2': 12100,\n",
       "             'fc2.weight': 12000,\n",
       "             'fc2.bias': 100,\n",
       "             'fc3': 1010,\n",
       "             'fc3.weight': 1000,\n",
       "             'fc3.bias': 10})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameter_count(net_glob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::max_pool2d encountered 2 time(s)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "653800"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FlopCountAnalysis(net_glob, inp).total()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::max_pool2d encountered 2 time(s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total FLOPs: 483240\n",
      "| module         | #parameters or shape   | #flops   |\n",
      "|:---------------|:-----------------------|:---------|\n",
      "| model          | 41.326K                | 0.483M   |\n",
      "|  conv1         |  0.38K                 |  0.294M  |\n",
      "|   conv1.weight |   (5, 3, 5, 5)         |          |\n",
      "|   conv1.bias   |   (5,)                 |          |\n",
      "|  conv2         |  1.512K                |  0.15M   |\n",
      "|   conv2.weight |   (12, 5, 5, 5)        |          |\n",
      "|   conv2.bias   |   (12,)                |          |\n",
      "|  fc1           |  30.1K                 |  30K     |\n",
      "|   fc1.weight   |   (100, 300)           |          |\n",
      "|   fc1.bias     |   (100,)               |          |\n",
      "|  fc2           |  8.484K                |  8.4K    |\n",
      "|   fc2.weight   |   (84, 100)            |          |\n",
      "|   fc2.bias     |   (84,)                |          |\n",
      "|  fc3           |  0.85K                 |  0.84K   |\n",
      "|   fc3.weight   |   (10, 84)             |          |\n",
      "|   fc3.bias     |   (10,)                |          |\n"
     ]
    }
   ],
   "source": [
    "# Mode 1\n",
    "# 6->5, 16 -> 12, 120 ->100, 100-> 84 \n",
    "class CNNCifar_1(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNNCifar_1, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 5, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(5, 12, 5)\n",
    "        self.fc1 = nn.Linear(12 * 5 * 5, 100)\n",
    "        self.fc2 = nn.Linear(100, 84)\n",
    "        self.fc3 = nn.Linear(84, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 12 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "net_glob = CNNCifar_1(num_classes = 10).to(\"cuda\")\n",
    "inp = torch.randn([1,3,32,32]).cuda()\n",
    "\n",
    "# log_probs = net_glob(inp)\n",
    "# inp = torch.randn([3,32,32]).cuda()\n",
    "flops_cnn = FlopCountAnalysis(net_glob, inp)\n",
    "print(\"Total FLOPs: \" + str(flops_cnn.total()))\n",
    "print(flop_count_table(flops_cnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'': 41326,\n",
       "             'conv1': 380,\n",
       "             'conv1.weight': 375,\n",
       "             'conv1.bias': 5,\n",
       "             'conv2': 1512,\n",
       "             'conv2.weight': 1500,\n",
       "             'conv2.bias': 12,\n",
       "             'fc1': 30100,\n",
       "             'fc1.weight': 30000,\n",
       "             'fc1.bias': 100,\n",
       "             'fc2': 8484,\n",
       "             'fc2.weight': 8400,\n",
       "             'fc2.bias': 84,\n",
       "             'fc3': 850,\n",
       "             'fc3.weight': 840,\n",
       "             'fc3.bias': 10})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameter_count(net_glob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::max_pool2d encountered 2 time(s)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "483240"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FlopCountAnalysis(net_glob, inp).total()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::max_pool2d encountered 2 time(s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total FLOPs: 490920\n",
      "| module         | #parameters or shape   | #flops   |\n",
      "|:---------------|:-----------------------|:---------|\n",
      "| model          | 49.026K                | 0.491M   |\n",
      "|  conv1         |  0.38K                 |  0.294M  |\n",
      "|   conv1.weight |   (5, 3, 5, 5)         |          |\n",
      "|   conv1.bias   |   (5,)                 |          |\n",
      "|  conv2         |  1.512K                |  0.15M   |\n",
      "|   conv2.weight |   (12, 5, 5, 5)        |          |\n",
      "|   conv2.bias   |   (12,)                |          |\n",
      "|  fc1           |  36.12K                |  36K     |\n",
      "|   fc1.weight   |   (120, 300)           |          |\n",
      "|   fc1.bias     |   (120,)               |          |\n",
      "|  fc2           |  10.164K               |  10.08K  |\n",
      "|   fc2.weight   |   (84, 120)            |          |\n",
      "|   fc2.bias     |   (84,)                |          |\n",
      "|  fc3           |  0.85K                 |  0.84K   |\n",
      "|   fc3.weight   |   (10, 84)             |          |\n",
      "|   fc3.bias     |   (10,)                |          |\n"
     ]
    }
   ],
   "source": [
    "# Mode 2\n",
    "# 6->5, 16 -> 12, _________, 100-> 84 \n",
    "class CNNCifar1(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNNCifar1, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 5, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(5, 12, 5)\n",
    "        self.fc1 = nn.Linear(12 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 12 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "net_glob = CNNCifar1(num_classes = 10).to(\"cuda\")\n",
    "inp = torch.randn([1,3,32,32]).cuda()\n",
    "\n",
    "# log_probs = net_glob(inp)\n",
    "# inp = torch.randn([3,32,32]).cuda()\n",
    "flops_cnn = FlopCountAnalysis(net_glob, inp)\n",
    "print(\"Total FLOPs: \" + str(flops_cnn.total()))\n",
    "print(flop_count_table(flops_cnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::max_pool2d encountered 2 time(s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total FLOPs: 493000\n",
      "| module         | #parameters or shape   | #flops   |\n",
      "|:---------------|:-----------------------|:---------|\n",
      "| model          | 51.122K                | 0.493M   |\n",
      "|  conv1         |  0.38K                 |  0.294M  |\n",
      "|   conv1.weight |   (5, 3, 5, 5)         |          |\n",
      "|   conv1.bias   |   (5,)                 |          |\n",
      "|  conv2         |  1.512K                |  0.15M   |\n",
      "|   conv2.weight |   (12, 5, 5, 5)        |          |\n",
      "|   conv2.bias   |   (12,)                |          |\n",
      "|  fc1           |  36.12K                |  36K     |\n",
      "|   fc1.weight   |   (120, 300)           |          |\n",
      "|   fc1.bias     |   (120,)               |          |\n",
      "|  fc2           |  12.1K                 |  12K     |\n",
      "|   fc2.weight   |   (100, 120)           |          |\n",
      "|   fc2.bias     |   (100,)               |          |\n",
      "|  fc3           |  1.01K                 |  1K      |\n",
      "|   fc3.weight   |   (10, 100)            |          |\n",
      "|   fc3.bias     |   (10,)                |          |\n"
     ]
    }
   ],
   "source": [
    "# Mode 3\n",
    "# 6->5, 16 -> 12, ___________________________\n",
    "class CNNCifar_3(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNNCifar_3, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 5, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(5, 12, 5)\n",
    "        self.fc1 = nn.Linear(12 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 100)\n",
    "        self.fc3 = nn.Linear(100, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 12 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "net_glob = CNNCifar_3(num_classes = 10).to(\"cuda\")\n",
    "inp = torch.randn([1,3,32,32]).cuda()\n",
    "\n",
    "# log_probs = net_glob(inp)\n",
    "# inp = torch.randn([3,32,32]).cuda()\n",
    "flops_cnn = FlopCountAnalysis(net_glob, inp)\n",
    "print(\"Total FLOPs: \" + str(flops_cnn.total()))\n",
    "print(flop_count_table(flops_cnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FlopCountAnalysis(net_glob, inp).total()\n",
    "parameter_count(net_glob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mode 4\n",
    "#  _______,________, 120 ->100, 100-> 84 \n",
    "class CNNCifar4(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNNCifar4, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 5, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(5, 12, 5)\n",
    "        self.fc1 = nn.Linear(12 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 12 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "net_glob = CNNCifar4(num_classes = 10).to(\"cuda\")\n",
    "inp = torch.randn([1,3,32,32]).cuda()\n",
    "\n",
    "# log_probs = net_glob(inp)\n",
    "# inp = torch.randn([3,32,32]).cuda()\n",
    "flops_cnn = FlopCountAnalysis(net_glob, inp)\n",
    "print(\"Total FLOPs: \" + str(flops_cnn.total()))\n",
    "print(flop_count_table(flops_cnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FlopCountAnalysis(net_glob, inp).total()\n",
    "parameter_count(net_glob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mode 1\n",
    "class CNNCifar2(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNNCifar2, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 5, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(5, 12, 5)\n",
    "        self.fc1 = nn.Linear(12 * 5 * 5, 100)\n",
    "        self.fc2 = nn.Linear(100, 84)\n",
    "        self.fc3 = nn.Linear(84, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 12 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::max_pool2d encountered 2 time(s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total FLOPs: 483240\n",
      "| module         | #parameters or shape   | #flops   |\n",
      "|:---------------|:-----------------------|:---------|\n",
      "| model          | 41.326K                | 0.483M   |\n",
      "|  conv1         |  0.38K                 |  0.294M  |\n",
      "|   conv1.weight |   (5, 3, 5, 5)         |          |\n",
      "|   conv1.bias   |   (5,)                 |          |\n",
      "|  conv2         |  1.512K                |  0.15M   |\n",
      "|   conv2.weight |   (12, 5, 5, 5)        |          |\n",
      "|   conv2.bias   |   (12,)                |          |\n",
      "|  fc1           |  30.1K                 |  30K     |\n",
      "|   fc1.weight   |   (100, 300)           |          |\n",
      "|   fc1.bias     |   (100,)               |          |\n",
      "|  fc2           |  8.484K                |  8.4K    |\n",
      "|   fc2.weight   |   (84, 100)            |          |\n",
      "|   fc2.bias     |   (84,)                |          |\n",
      "|  fc3           |  0.85K                 |  0.84K   |\n",
      "|   fc3.weight   |   (10, 84)             |          |\n",
      "|   fc3.bias     |   (10,)                |          |\n"
     ]
    }
   ],
   "source": [
    "net_glob = CNNCifar2(num_classes = 10).to(\"cuda\")\n",
    "inp = torch.randn([1,3,32,32]).cuda()\n",
    "\n",
    "# log_probs = net_glob(inp)\n",
    "# inp = torch.randn([3,32,32]).cuda()\n",
    "flops_cnn = FlopCountAnalysis(net_glob, inp)\n",
    "print(\"Total FLOPs: \" + str(flops_cnn.total()))\n",
    "print(flop_count_table(flops_cnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mode 2\n",
    "class CNNCifar3(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNNCifar3, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 5, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(5, 12, 5)\n",
    "        self.fc1 = nn.Linear(12 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 12 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::max_pool2d encountered 2 time(s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total FLOPs: 490920\n",
      "| module         | #parameters or shape   | #flops   |\n",
      "|:---------------|:-----------------------|:---------|\n",
      "| model          | 49.026K                | 0.491M   |\n",
      "|  conv1         |  0.38K                 |  0.294M  |\n",
      "|   conv1.weight |   (5, 3, 5, 5)         |          |\n",
      "|   conv1.bias   |   (5,)                 |          |\n",
      "|  conv2         |  1.512K                |  0.15M   |\n",
      "|   conv2.weight |   (12, 5, 5, 5)        |          |\n",
      "|   conv2.bias   |   (12,)                |          |\n",
      "|  fc1           |  36.12K                |  36K     |\n",
      "|   fc1.weight   |   (120, 300)           |          |\n",
      "|   fc1.bias     |   (120,)               |          |\n",
      "|  fc2           |  10.164K               |  10.08K  |\n",
      "|   fc2.weight   |   (84, 120)            |          |\n",
      "|   fc2.bias     |   (84,)                |          |\n",
      "|  fc3           |  0.85K                 |  0.84K   |\n",
      "|   fc3.weight   |   (10, 84)             |          |\n",
      "|   fc3.bias     |   (10,)                |          |\n"
     ]
    }
   ],
   "source": [
    "net_glob = CNNCifar3(num_classes = 10).to(\"cuda\")\n",
    "inp = torch.randn([1,3,32,32]).cuda()\n",
    "\n",
    "# log_probs = net_glob(inp)\n",
    "# inp = torch.randn([3,32,32]).cuda()\n",
    "flops_cnn = FlopCountAnalysis(net_glob, inp)\n",
    "print(\"Total FLOPs: \" + str(flops_cnn.total()))\n",
    "print(flop_count_table(flops_cnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mode 3\n",
    "class CNNCifar4(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNNCifar4, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 5, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(5, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::max_pool2d encountered 2 time(s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total FLOPs: 552920\n",
      "| module         | #parameters or shape   | #flops   |\n",
      "|:---------------|:-----------------------|:---------|\n",
      "| model          | 61.53K                 | 0.553M   |\n",
      "|  conv1         |  0.38K                 |  0.294M  |\n",
      "|   conv1.weight |   (5, 3, 5, 5)         |          |\n",
      "|   conv1.bias   |   (5,)                 |          |\n",
      "|  conv2         |  2.016K                |  0.2M    |\n",
      "|   conv2.weight |   (16, 5, 5, 5)        |          |\n",
      "|   conv2.bias   |   (16,)                |          |\n",
      "|  fc1           |  48.12K                |  48K     |\n",
      "|   fc1.weight   |   (120, 400)           |          |\n",
      "|   fc1.bias     |   (120,)               |          |\n",
      "|  fc2           |  10.164K               |  10.08K  |\n",
      "|   fc2.weight   |   (84, 120)            |          |\n",
      "|   fc2.bias     |   (84,)                |          |\n",
      "|  fc3           |  0.85K                 |  0.84K   |\n",
      "|   fc3.weight   |   (10, 84)             |          |\n",
      "|   fc3.bias     |   (10,)                |          |\n"
     ]
    }
   ],
   "source": [
    "net_glob = CNNCifar4(num_classes = 10).to(\"cuda\")\n",
    "inp = torch.randn([1,3,32,32]).cuda()\n",
    "\n",
    "# log_probs = net_glob(inp)\n",
    "# inp = torch.randn([3,32,32]).cuda()\n",
    "flops_cnn = FlopCountAnalysis(net_glob, inp)\n",
    "print(\"Total FLOPs: \" + str(flops_cnn.total()))\n",
    "print(flop_count_table(flops_cnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mode 4\n",
    "class CNNCifar5(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNNCifar5, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 100)\n",
    "        self.fc2 = nn.Linear(100, 84)\n",
    "        self.fc3 = nn.Linear(84, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::max_pool2d encountered 2 time(s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total FLOPs: 642040\n",
      "| module         | #parameters or shape   | #flops   |\n",
      "|:---------------|:-----------------------|:---------|\n",
      "| model          | 52.306K                | 0.642M   |\n",
      "|  conv1         |  0.456K                |  0.353M  |\n",
      "|   conv1.weight |   (6, 3, 5, 5)         |          |\n",
      "|   conv1.bias   |   (6,)                 |          |\n",
      "|  conv2         |  2.416K                |  0.24M   |\n",
      "|   conv2.weight |   (16, 6, 5, 5)        |          |\n",
      "|   conv2.bias   |   (16,)                |          |\n",
      "|  fc1           |  40.1K                 |  40K     |\n",
      "|   fc1.weight   |   (100, 400)           |          |\n",
      "|   fc1.bias     |   (100,)               |          |\n",
      "|  fc2           |  8.484K                |  8.4K    |\n",
      "|   fc2.weight   |   (84, 100)            |          |\n",
      "|   fc2.bias     |   (84,)                |          |\n",
      "|  fc3           |  0.85K                 |  0.84K   |\n",
      "|   fc3.weight   |   (10, 84)             |          |\n",
      "|   fc3.bias     |   (10,)                |          |\n"
     ]
    }
   ],
   "source": [
    "net_glob = CNNCifar5(num_classes = 10).to(\"cuda\")\n",
    "inp = torch.randn([1,3,32,32]).cuda()\n",
    "\n",
    "# log_probs = net_glob(inp)\n",
    "# inp = torch.randn([3,32,32]).cuda()\n",
    "flops_cnn = FlopCountAnalysis(net_glob, inp)\n",
    "print(\"Total FLOPs: \" + str(flops_cnn.total()))\n",
    "print(flop_count_table(flops_cnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_from_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP_from_CNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58920\n",
      "| module       | #parameters or shape   | #flops   |\n",
      "|:-------------|:-----------------------|:---------|\n",
      "| model        | 59.134K                | 58.92K   |\n",
      "|  fc1         |  48.12K                |  48K     |\n",
      "|   fc1.weight |   (120, 400)           |          |\n",
      "|   fc1.bias   |   (120,)               |          |\n",
      "|  fc2         |  10.164K               |  10.08K  |\n",
      "|   fc2.weight |   (84, 120)            |          |\n",
      "|   fc2.bias   |   (84,)                |          |\n",
      "|  fc3         |  0.85K                 |  0.84K   |\n",
      "|   fc3.weight |   (10, 84)             |          |\n",
      "|   fc3.bias   |   (10,)                |          |\n"
     ]
    }
   ],
   "source": [
    "net_glob = MLP_from_CNN().to(\"cuda\")\n",
    "inp = torch.randn(400,1).cuda()\n",
    "flops1 = FlopCountAnalysis(net_glob, inp)\n",
    "print(flops1.total())\n",
    "print(flop_count_table(flops1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::max_pool2d encountered 2 time(s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total FLOPs: 552920\n",
      "| module         | #parameters or shape   | #flops   |\n",
      "|:---------------|:-----------------------|:---------|\n",
      "| model          | 61.53K                 | 0.553M   |\n",
      "|  conv1         |  0.38K                 |  0.294M  |\n",
      "|   conv1.weight |   (5, 3, 5, 5)         |          |\n",
      "|   conv1.bias   |   (5,)                 |          |\n",
      "|  conv2         |  2.016K                |  0.2M    |\n",
      "|   conv2.weight |   (16, 5, 5, 5)        |          |\n",
      "|   conv2.bias   |   (16,)                |          |\n",
      "|  fc1           |  48.12K                |  48K     |\n",
      "|   fc1.weight   |   (120, 400)           |          |\n",
      "|   fc1.bias     |   (120,)               |          |\n",
      "|  fc2           |  10.164K               |  10.08K  |\n",
      "|   fc2.weight   |   (84, 120)            |          |\n",
      "|   fc2.bias     |   (84,)                |          |\n",
      "|  fc3           |  0.85K                 |  0.84K   |\n",
      "|   fc3.weight   |   (10, 84)             |          |\n",
      "|   fc3.bias     |   (10,)                |          |\n"
     ]
    }
   ],
   "source": [
    "class CNNCifar2(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNNCifar2, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 5, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(5, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "net_glob = CNNCifar2(num_classes = 10).to(\"cuda\")\n",
    "inp = torch.randn([1,3,32,32]).cuda()\n",
    "\n",
    "# log_probs = net_glob(inp)\n",
    "# inp = torch.randn([3,32,32]).cuda()\n",
    "flops1 = FlopCountAnalysis(net_glob, inp)\n",
    "print(\"Total FLOPs: \" + str(flops1.total()))\n",
    "print(flop_count_table(flops1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#39200 *4 -> 156800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, dim_in, dim_hidden, dim_out):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layer_input = nn.Linear(dim_in, dim_hidden)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout()\n",
    "        self.layer_hidden = nn.Linear(dim_hidden, dim_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, x.shape[1]*x.shape[-2]*x.shape[-1])\n",
    "        x = self.layer_input(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer_hidden(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_glob = MLP2(dim_in=784, dim_hidden= 150, dim_out=10).to(\"cuda\")\n",
    "inp = torch.randn(784,1).cuda()\n",
    "inp2 = torch.randn(200,1).cuda()\n",
    "flops1 = FlopCountAnalysis(net_glob, (inp,inp2))\n",
    "flops1.total()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::mul encountered 2 time(s)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "158800"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_glob = MLP(dim_in=784, dim_hidden= 200, dim_out=10).to(\"cuda\")\n",
    "inp = torch.randn(784,1).cuda()\n",
    "flops1 = FlopCountAnalysis(net_glob, inp)\n",
    "flops1.total()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::mul encountered 2 time(s)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "158800"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FlopCountAnalysis(net_glob, inp).total()\n",
    "parameter_count(net_glob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'': 159010,\n",
       "             'layer_input': 157000,\n",
       "             'layer_input.weight': 156800,\n",
       "             'layer_input.bias': 200,\n",
       "             'layer_hidden': 2010,\n",
       "             'layer_hidden.weight': 2000,\n",
       "             'layer_hidden.bias': 10})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameter_count(net_glob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| module                | #parameters or shape   | #flops   |\n",
      "|:----------------------|:-----------------------|:---------|\n",
      "| model                 | 0.159M                 | 0.159M   |\n",
      "|  layer_input          |  0.157M                |  0.157M  |\n",
      "|   layer_input.weight  |   (200, 784)           |          |\n",
      "|   layer_input.bias    |   (200,)               |          |\n",
      "|  layer_hidden         |  2.01K                 |  2K      |\n",
      "|   layer_hidden.weight |   (10, 200)            |          |\n",
      "|   layer_hidden.bias   |   (10,)                |          |\n"
     ]
    }
   ],
   "source": [
    "#GlobalNet 200 neurons in hidden layer\n",
    "print(flop_count_table(flops1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weights Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP2(nn.Module):\n",
    "    def __init__(self, dim_in=784, dim_hidden=150, dim_out=10):\n",
    "        super(MLP2, self).__init__()\n",
    "        self.layer_input = nn.Linear(dim_in, dim_hidden)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout()\n",
    "        self.layer_hidden = nn.Linear(dim_hidden, dim_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, x.shape[1]*x.shape[-2]*x.shape[-1])\n",
    "        x = self.layer_input(x)\n",
    "        x = self.layer_hidden(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| module                | #parameters or shape   | #flops   |\n",
      "|:----------------------|:-----------------------|:---------|\n",
      "| model                 | 0.119M                 | 0.119M   |\n",
      "|  layer_input          |  0.118M                |  0.118M  |\n",
      "|   layer_input.weight  |   (150, 784)           |          |\n",
      "|   layer_input.bias    |   (150,)               |          |\n",
      "|  layer_hidden         |  1.51K                 |  1.5K    |\n",
      "|   layer_hidden.weight |   (10, 150)            |          |\n",
      "|   layer_hidden.bias   |   (10,)                |          |\n"
     ]
    }
   ],
   "source": [
    "net_glob = MLP2(dim_in=784, dim_hidden= 150, dim_out=10).to(\"cuda\")\n",
    "inp = torch.randn(784,1).cuda()\n",
    "flops1 = FlopCountAnalysis(net_glob, inp)\n",
    "print(flop_count_table(flops1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::mul encountered 2 time(s)\n",
      "Unsupported operator aten::add_ encountered 1 time(s)\n",
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "dropout, layer_hidden, relu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "117600"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_glob = MLP3(dim_in=784, dim_hidden= 150, dim_out=10).to(\"cuda\")\n",
    "inp = torch.randn(784,1).cuda()\n",
    "flops1 = FlopCountAnalysis(net_glob, inp)\n",
    "flops1.total()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixed SubNetwork, Neuron Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::mul encountered 2 time(s)\n"
     ]
    }
   ],
   "source": [
    "n1 = MLP(dim_in=784, dim_hidden=150, dim_out=10).to(\"cuda\")\n",
    "inp = torch.randn(784,1).cuda()\n",
    "flops2 = FlopCountAnalysis(n1, inp).total()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'': 119260,\n",
       "             'layer_input': 117750,\n",
       "             'layer_input.weight': 117600,\n",
       "             'layer_input.bias': 150,\n",
       "             'layer_hidden': 1510,\n",
       "             'layer_hidden.weight': 1500,\n",
       "             'layer_hidden.bias': 10})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameter_count(n1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fvcore.nn import parameter_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::mul encountered 2 time(s)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "119100"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FlopCountAnalysis(n1, inp).total()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'': 119260,\n",
       "             'layer_input': 117750,\n",
       "             'layer_input.weight': 117600,\n",
       "             'layer_input.bias': 150,\n",
       "             'layer_hidden': 1510,\n",
       "             'layer_hidden.weight': 1500,\n",
       "             'layer_hidden.bias': 10})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameter_count(n1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| module                | #parameters or shape   | #flops   |\n",
      "|:----------------------|:-----------------------|:---------|\n",
      "| model                 | 0.119M                 | 0.119M   |\n",
      "|  layer_input          |  0.118M                |  0.118M  |\n",
      "|   layer_input.weight  |   (150, 784)           |          |\n",
      "|   layer_input.bias    |   (150,)               |          |\n",
      "|  layer_hidden         |  1.51K                 |  1.5K    |\n",
      "|   layer_hidden.weight |   (10, 150)            |          |\n",
      "|   layer_hidden.bias   |   (10,)                |          |\n"
     ]
    }
   ],
   "source": [
    "#N2 N3 N4 150 neurons in hidden layer\n",
    "print(flop_count_table(flops2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::mul encountered 2 time(s)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "79400"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n1 = MLP(dim_in=784, dim_hidden=100, dim_out=10).to(\"cuda\")\n",
    "inp = torch.randn(784,1).cuda()\n",
    "flops3 = FlopCountAnalysis(n1, inp)\n",
    "flops3.total()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| module                | #parameters or shape   | #flops   |\n",
      "|:----------------------|:-----------------------|:---------|\n",
      "| model                 | 79.51K                 | 79.4K    |\n",
      "|  layer_input          |  78.5K                 |  78.4K   |\n",
      "|   layer_input.weight  |   (100, 784)           |          |\n",
      "|   layer_input.bias    |   (100,)               |          |\n",
      "|  layer_hidden         |  1.01K                 |  1K      |\n",
      "|   layer_hidden.weight |   (10, 100)            |          |\n",
      "|   layer_hidden.bias   |   (10,)                |          |\n"
     ]
    }
   ],
   "source": [
    "print(flop_count_table(flops3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| module                | #parameters or shape   | #flops   |\n",
      "|:----------------------|:-----------------------|:---------|\n",
      "| model                 | 79.51K                 | 79.4K    |\n",
      "|  layer_input          |  78.5K                 |  78.4K   |\n",
      "|   layer_input.weight  |   (100, 784)           |          |\n",
      "|   layer_input.bias    |   (100,)               |          |\n",
      "|  layer_hidden         |  1.01K                 |  1K      |\n",
      "|   layer_hidden.weight |   (10, 100)            |          |\n",
      "|   layer_hidden.bias   |   (10,)                |          |\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "setting_array = [8,0,0,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 80\n",
      "80 80\n",
      "80 80\n",
      "100 100\n"
     ]
    }
   ],
   "source": [
    "a = 10 * setting_array[0]\n",
    "b = a + 10 * setting_array[1]\n",
    "c = b + 10 * setting_array[2]\n",
    "\n",
    "\n",
    "print(0,a)\n",
    "print(a,b)\n",
    "print(b,c)\n",
    "print(d,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8002'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "setting = str(setting_array).replace(\",\",\"\").replace(\" \",\"\").replace(\"[\",\"\").replace(\"]\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('temp.txt', 'a+') as f:\n",
    "    print('printing to a file.', file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import winsound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration = 1000  # milliseconds\n",
    "freq = 940  # Hz\n",
    "winsound.Beep(freq, 500)\n",
    "winsound.Beep(38, 500)\n",
    "winsound.Beep(freq, 500)\n",
    "winsound.Beep(38, 500)\n",
    "winsound.Beep(freq, 500)\n",
    "winsound.Beep(38, 500)\n",
    "winsound.Beep(freq, 500)\n",
    "winsound.Beep(38, 500)\n",
    "winsound.Beep(freq, 500)\n",
    "winsound.Beep(38, 500)\n",
    "winsound.Beep(freq, 500)\n",
    "winsound.Beep(38, 500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
